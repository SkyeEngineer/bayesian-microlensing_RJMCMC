<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>sampling API documentation</title>
<meta name="description" content="Adaptive Reversible-Jump Metropolis Hastings for microlensing â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sampling</code></h1>
</header>
<section id="section-intro">
<p>Adaptive Reversible-Jump Metropolis Hastings for microlensing.</p>
<p>Implements algorithms for bayesian sampling. Uses the main
classes: State, Chain, and Model to ensure generality and possible
extension to different RJMH algorithms.</p>
<p>Typical usage example:</p>
<p>See modules: expected_binary and expected_robustness</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Adaptive Reversible-Jump Metropolis Hastings for microlensing.

Implements algorithms for bayesian sampling. Uses the main 
classes: State, Chain, and Model to ensure generality and possible
extension to different RJMH algorithms.

  Typical usage example:

  See modules: expected_binary and expected_robustness 
&#34;&#34;&#34;

import MulensModel as mm 
import math
import random
import numpy as np
from scipy.stats import lognorm, loguniform, uniform, multivariate_normal
from copy import deepcopy
from types import MethodType


class Uniform(object):
    &#34;&#34;&#34;A uniform distribution.

    Attributes:
        lb: A float lower bound for support.
        rb: A float upper bound for support.
    &#34;&#34;&#34;

    def __init__(self, left, right):
        &#34;&#34;&#34;Initialises Uniform with bounds and sampler.&#34;&#34;&#34;
        self.lb = left
        self.rb = right
        self.dist = uniform(left, right)

    def in_bound(self, x):
        &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
        if self.lb &lt;= x &lt;= self.rb: return 1
        else: return 0

    def log_pdf(self, x):
        &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
        return self.dist.logpdf(x)


class Log_Uniform(object):
    &#34;&#34;&#34;A log uniform distribution.

    The log of the data is uniformly distributed.

    Attributes:
        lb: A float lower bound for support.
        rb: A float upper bound for support.
    &#34;&#34;&#34;

    def __init__(self, left, right):
        &#34;&#34;&#34;Initialises Log uniform with bounds and sampler.&#34;&#34;&#34;
        self.lb = left
        self.rb = right
        self.dist = loguniform(left, right)

    def in_bound(self, x):
        &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
        if self.lb &lt;= x &lt;= self.rb: return 1
        else: return 0

    def log_pdf(self, x):
        &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
        return self.dist.logpdf(x)


class Truncated_Log_Normal(object):
    &#34;&#34;&#34;A truncated log normal distribution.

    The log of the data is normally distributed, and the data is constrained.

    Attributes:
        lb: A float lower bound for support.
        rb: A float upper bound for support.
    &#34;&#34;&#34;

    def __init__(self, left, right, mu, sd):
        &#34;&#34;&#34;Initialises Truncated log normal with bounds and sampler.

        Args:
            mu: The scalar mean of the underlying normal distrubtion in true 
                space.
            sd: The scalar standard deviation of the underlying normal 
                distribution in true space.
        &#34;&#34;&#34;
        self.lb = left
        self.rb = right
        self.dist = lognorm(scale = np.exp(np.log(mu)), s = (np.log(sd))) # Scipy shape parameters.

        # Probability that is otherwise truncated to zero, distributed uniformly (aprroximation).
        self.truncation = (self.dist.cdf(left) + 1 - self.dist.cdf(right)) / (right - left)

    def in_bound(self, x):
        &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
        if self.lb &lt;= x &lt;= self.rb: return 1
        else: return 0

    def log_pdf(self, x):
        &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
        if self.lb &lt;= x &lt;= self.rb: return np.log(self.dist.pdf(x) + self.truncation)
        else: return -math.inf # If out of support.


class State(object):
    &#34;&#34;&#34;A sampled state from a model&#39;s probability distribution.

    Describes a point in both scaled and unscaled space. The scaling is 
    hardcoded but can be extended per application. Currently log10 scaling 
    the fourth parameter. In microlensing applications, this is q,
    the mass ratio.

    Attributes:
        truth: A list of parameter values for the state, in true space.
        scaled: A list of parameter values for the state, in scaled space.
        D: The integer dimensionality of the state.
    &#34;&#34;&#34;

    def __init__(self, truth = None, scaled = None):
        &#34;&#34;&#34;Initialises state with truth, scaled, and D values.

        Args:
            either a list of parameter values in the true or scaled states.
        &#34;&#34;&#34;        
        if truth is not None:
            self.truth = truth
            self.D = len(truth)

            self.scaled = deepcopy(self.truth)
            for p in range(self.D):
                if p == 3:
                    self.scaled[p] = np.log10(self.truth[p])
        
        elif scaled is not None:
            self.scaled = scaled
            self.D = len(scaled)

            self.truth = deepcopy(self.scaled)
            for p in range(self.D):
                if p == 3:
                    self.truth[p] = 10**(self.scaled[p])

        else:   raise ValueError(&#34;Assigned null state&#34;)


class Chain(object):
    &#34;&#34;&#34;A collection of states.

    Describes a markov chain, perhaps from a joint model space.

    Attributes:
        states: A list of state objects in the chain.
        model_indices: A list of the models the states are from. 
        n: The number of states in the chain.
    &#34;&#34;&#34;

    def __init__(self, m, state):
        &#34;&#34;&#34;Initialises the chain with one state from one model.

        Args:
            state: The state object.
            m: The index of the model the state is from.
        &#34;&#34;&#34;
        self.states = [state]
        self.model_indices = [m]
        self.n = 1

    def add_general_state(self, m, state):
        &#34;&#34;&#34;Adds a state in a model to the chain.

        Args:
            state: The state object.
            m: The index of the model the state is from.
        &#34;&#34;&#34;
        self.states.append(state)
        self.model_indices.append(m)
        self.n += 1
        return

    def states_array(self, scaled = True):
        &#34;&#34;&#34;Creates a numpy array of all states in the chain.

        Args:
            scale: (Optional) whether the array should be in scaled or true 
                    space (Boolean).

        Returns:
            chain_array: The numpy array of all state parameters. Columns are
                        states, rows are parameters for all states.
        &#34;&#34;&#34;
        n_states = len(self.states)
        D_state = len(self.states[-1].scaled)
        
        chain_array = np.zeros((D_state, n_states))

        if scaled:
            for i in range(n_states):
                chain_array[:, i] = self.states[i].scaled

        else:
            for i in range(n_states):
                chain_array[:, i] = self.states[i].truth

        return chain_array


class Model(object):
    &#34;&#34;&#34;A model to describe a probability distribution.

    Contains a chain of states from this model, as well as information
    from this. Adapts a covariance matrix iteratively with each new state,
    and stores a guess at a maximum posterior density estimate.

    Attributes:
        m: The integer model index.
        D: The integer dimensionality of a state in the model.
        priors: List of prior distributions for state parameter values.
        sampled: A chain of states sampled from the model&#39;s distribution.
        scaled_avg_state: The scaled average parameter values of the chain.
        center: The state of the best guess at a maximum posterior density.
        covariance: The current covariance matrix, based on all states.
        covariances: A list of all previous covariance matrices.
        acc: A list of binary values, 1 if the state proposed was accepted,
            0 if it was rejected.
        data: A MulensData object for photometry readings from the 
            microlensing event.
        log_likelihood: A function to calculate the log likelihood a state is
            from this model.
        I: An identity matrix the size of D.
        s: A scalar (see Haario et al 2001).
    &#34;&#34;&#34;

    def __init__(self, m, D, Center, priors, covariance, data, log_likelihood_fnc):
        &#34;&#34;&#34;Initialises the model.&#34;&#34;&#34;
        self.m = m
        self.D = D
        self.priors = priors
        self.Center = Center
        self.Sampled = Chain(m, Center)
        self.scaled_avg_state = Center.scaled
        self.acc = [1] # First state always accepted
        self.covariance = covariance
        self.covariances = [covariance]

        self.data = data
        # Model&#39;s custom likelihood function
        self.log_likelihood = MethodType(log_likelihood_fnc, self)

        self.I = np.identity(D)
        self.s = 2.4**2 / D # Arbitrary(ish), good value from Haario et al 2001.
    
    def add_state(self, theta, adapt = True):
        &#34;&#34;&#34;Adds a sampled state to the model.

        Args:
            theta: The state to add.
            adapt: (Optional) whether to adjust the covariance matrix, based
                on the new state (Boolean).
        &#34;&#34;&#34;
        self.Sampled.n += 1
        self.Sampled.states.append(theta)

        if adapt:
            self.covariance = iterative_covariance(self.covariance, theta.scaled, self.scaled_avg_state, self.Sampled.n, self.s, self.I)

        self.covariances.append(self.covariance)
        self.scaled_avg_state = iterative_mean(self.scaled_avg_state, theta.scaled, self.Sampled.n)

        return

    def log_likelihood(self, theta):
        &#34;&#34;&#34;Empty method for object model dependant assignment with MethodType.&#34;&#34;&#34;
        raise ValueError(&#34;No likelihood method assigned for model&#34;)

    def log_prior_density(self, theta, v = None, v_D = None):
        &#34;&#34;&#34;Calculates the log prior density of a state in the model.

        Optionally adjusts this log density when using auxilliary vriables.

        Args:
            theta: The state to calculate the log prior density for.
            v: (Optional) The state of all auxiliary variables.
            v_D: (Optional) the integer dimensionality of to use to adjust v.

        Returns:
            log_prior_product: The log prior probability density.
        &#34;&#34;&#34;    
        log_prior_product = 0.

        # cycle through parameters
        for p in range(self.D):

            # product using log rules
            log_prior_product += (self.priors[p].log_pdf(theta.truth[p]))

        # cycle through auxiliary parameters if v and v_D passed
        if v is not None or v_D is not None:
            if v is not None and v_D is not None:
                for p in range(self.D, v_D):
                    
                    # product using log rules
                    log_prior_product += (self.priors[p].log_pdf(v.truth[p]))

            else: raise ValueError(&#34;Only one of v or v_D passed.&#34;)

        return log_prior_product


def iterative_mean(x_mu, x, n):
    return (x_mu * n + x)/(n + 1)

def iterative_covariance(cov, x, x_mu, n, s, I, eps = 1e-12):
    return (n-1)/n * cov + s/(n+1) * np.outer(x - x_mu, x - x_mu) + s*eps*I/n

def check_symmetric(A, tol = 1e-16):
    return np.all(np.abs(A-A.T) &lt; tol)



def gaussian_proposal(theta, covariance):
    &#34;&#34;&#34;Samples a gaussian move.&#34;&#34;&#34;
    return multivariate_normal.rvs(mean = theta, cov = covariance)

def adapt_MH(Model, warm_up, iterations, user_feedback = False):
    &#34;&#34;&#34;Performs Adaptive Metropolis Hastings.
    
    Produces a posterior distribution by adapting the proposal process within 
    one model, as described in Haario et al (2001).

    Args:
        Model: The model object to sample the distrbution from.
        warm_up: The integer number of steps without adaption.
        iterations: The integer number of steps with adaption.
        user_feedback: (Optional) whether or not to print porgress (Boolean).

    Returns:
        BestTheta: The state producing the best posterior density visited.
        log_best_posterior: The best log posterior density visited. 
    &#34;&#34;&#34;

    if warm_up &lt; 5:
        raise ValueError(&#34;Not enough iterations to safely establish an empirical covariance matrix.&#34;)
    
    Theta = Model.center
    BestTheta = Theta

    # Initial propbability values.
    log_likelihood = Model.log_likelihood(Theta)
    log_prior = Model.log_prior_density(Theta)
    log_best_posterior = log_likelihood + log_prior

    # Warm up walk to establish an empirical covariance.
    for i in range(1, warm_up):

        # Propose a new state and calculate the resulting density.
        Proposed = State(scaled = gaussian_proposal(Theta.scaled, Model.covariance))
        log_likelihood_proposed = Model.log_likelihood(Proposed)
        log_prior_proposed = Model.log_prior_density(Proposed)

        # Metropolis acceptance criterion.
        if random.random() &lt; np.exp(log_likelihood_proposed - log_likelihood + log_prior_proposed - log_prior):
            # Accept proposal.
            Theta = Proposed
            log_likelihood = log_likelihood_proposed
            Model.acc.append(1)

            # store best state
            log_posterior = log_likelihood_proposed + log_prior_proposed
            if log_best_posterior &lt; log_posterior:
                log_best_posterior = log_posterior
                BestTheta = Theta

        else: Model.acc.append(0) # reject proposal
        
        # update storage
        Model.add_state(Theta, adapt = False)

    # Calculate intial empirical covariance matrix.
    Model.covariance = np.cov(Model.sampled.states_array(scaled = True))
    Model.covariances.pop()
    Model.covariances.append(Model.covariance)

    # Perform adaptive walk.
    for i in range(warm_up, iterations):

        if user_feedback:
            cf = i / (iterations - 1)
            print(f&#39;log score: {log_best_posterior:.4f}, progress: [{&#34;#&#34;*round(50*cf)+&#34;-&#34;*round(50*(1-cf))}] {100.*cf:.2f}%\r&#39;, end=&#34;&#34;)

        # Propose a new state and calculate the resulting density.
        Proposed = State(scaled = gaussian_proposal(Theta.scaled, Model.covariance))
        log_likelihood_proposed = Model.log_likelihood(Proposed)
        log_prior_proposed = Model.log_prior_density(Proposed)

        # Metropolis acceptance criterion.
        if random.random() &lt; np.exp(log_likelihood_proposed - log_likelihood + log_prior_proposed - log_prior):
            # Accept proposal.
            Theta = Proposed
            log_likelihood = log_likelihood_proposed
            Model.acc.append(1)

            # Store the best state.
            log_posterior = log_likelihood_proposed + log_prior_proposed
            if log_best_posterior &lt; log_posterior:
                log_best_posterior = log_posterior
                BestTheta = Theta

        else: Model.acc.append(0) # Reject proposal.
        
        # Update model chain.
        Model.add_state(Theta, adapt = True)

    if user_feedback:
        print(f&#34;\n model: {Model.m}, average acc: {(np.sum(Model.acc) / (iterations + warm_up)):4f}, best score: {log_best_posterior:.4f}&#34;)

    return BestTheta, log_best_posterior


def adapt_RJMH_proposal(Model, ProposedModel, Theta, lv):
    &#34;&#34;&#34;Performs an Adaptive Reversible-Jump Metropolis Hastings proposal.
    
    Args:
        Model: The model to jump from.
        ProposedModel: The model to jump to.
        Theta: The state to jump from.
        lv: A list of the current auxilliary variables center divergence.

    Returns:
        ProposedTheta: A state proposed to jump to.
    &#34;&#34;&#34;
    l = Theta.scaled - Model.Center.scaled # Offset from initial model&#39;s centre.

    if Model.m == ProposedModel.m: # Intra-model move.

        # Use the covariance at the proposed model&#39;s center for local shape.
        u = gaussian_proposal(np.zeros((ProposedModel.D)), ProposedModel.covariance)
        ProposedTheta = u + l + ProposedModel.Center.scaled
        
        return ProposedTheta

    else: # Inter-model move.
        
        s = abs(Model.D - ProposedModel.D) # Subset size.

        # Use superset model covariance
        if ProposedModel.D &gt; Model.D: # Proposed is superset
            cov = ProposedModel.covariance
        else: # Proposed is subset
            cov = Model.covariance

        c_11 = cov[:s, :s] # Covariance matrix of shared parameters.
        c_12 = cov[:s, s:] # Covariances, not variances.
        c_21 = cov[s:, :s] # Same as above.
        c_22 = cov[s:, s:] # Covariance matrix of non-shared.
        c_22_inv = np.linalg.inv(c_22)

        conditioned_cov = c_11 - c_12.dot(c_22_inv).dot(c_21)

        if ProposedModel.D &lt; Model.D: # Jump to smaller model. Fix non-shared parameters.

            u = gaussian_proposal(np.zeros((s)), conditioned_cov)
            proposed_theta = u + l[:s] + ProposedModel.Center.scaled

            return proposed_theta

        if ProposedModel.D &gt; Model.D: # Jump to larger model. Append v.

            u = gaussian_proposal(np.zeros((s)), conditioned_cov)
            shared_map = u + l[:s] + ProposedModel.Center.scaled[:s]
            non_shared_map = lv[s:] + ProposedModel.Center.scaled[s:]
            map = np.concatenate((shared_map, non_shared_map))
            proposed_theta = map

            return proposed_theta


def initialise_RJMH_model(EmptyModel, warm_up, iterations, n_repeat, user_feedback = False):
    &#34;&#34;&#34;Prepares a model for the adaptive RJ algorithm.
    
    Repeats the adaptive MH warmup process for a model, storing the best run.

    Args:
        EmptyModel: The initialised model object.
        warm_up: The integer number of non-adaptive steps.
        iterations: The integer number of adaptive steps.
        n_repeat: The integer number of times to try for a better run.
        user_feedback: (Optional) whether to print progress (Boolean).

    Returns:
        IncumbentModel: The model with the states from the best run.
    &#34;&#34;&#34;

    inc_log_best_posterior = -math.inf # Initialise incumbent posterior to always lose

    for i in range(n_repeat):
        
        if user_feedback:
            print(&#34;Running the &#34;+str(i+1)+&#34;/&#34;+str(n_repeat)+&#34;th initialisation per model\n&#34;)

        Model = deepcopy(EmptyModel) # Fresh model.

        # Run adaptive MH.
        BestTheta, log_best_posterior = adapt_MH(Model, warm_up, iterations, user_feedback = user_feedback)

        # Keep the best posterior density run.
        if inc_log_best_posterior &lt; log_best_posterior:
            IncumbentModel = Model
            IncumbentModel.Center = BestTheta

    return IncumbentModel


def adapt_RJMH(models, adapt_MH_warm_up, adapt_MH, initial_n, iterations, user_feedback = False):
    &#34;&#34;&#34;Samples from a joint distribution of models.
    
    Initialises each model with multiple adaptive MH runs. Then uses the resulting
    covariances to run adaptive RJMH on all models.

    Args:
        models: A list of model objects to sample from. 
            Should be sorted by increasing dimensionality.
        adapt_MH_warm_up: The integer number of non-adaptive steps to initilaise with.
        adapt_MH: The integer number of adaptive steps to initialise with.
        n_repeat: The integer number of times to try for a better initial run.
        iterations: The integer number of adaptive RJMH steps.
        user_feedback: (Optional) whether to print progress (Boolean).

    Returns:
        JointModelChain: A generalised chain with states from any model.
        total_acc: A list of binary values, 1 if the state proposed was accepted,
            0 if it was rejected, associated with the joint model.
    &#34;&#34;&#34;

    # Initialise model chains.
    for Model in models:
        Model = initialise_RJMH_model(Model, adapt_MH_warm_up, adapt_MH, initial_n, user_feedback = user_feedback)

    random.seed(42)

    # Choose a random model to start in.
    Model = random.choice(models)
    Theta = Model.Sampled.states[-1] # Final state in model&#39;s warmup chain.

    v = models[-1].Sampled.states[-1] # Auxiliary variables final state in super set model
    lv = models[-1].Sampled.states[-1].scaled - models[-1].Center.scaled # auxiliary variables offset from center

    # Create joint model as initial theta appended to auxiliary variables.
    initial_superset = models[-1].D - Model.D
    if initial_superset &gt; 0: # If random choice was a subset model
        Theta_v = np.concatenate((Theta.scaled, models[-1].Sampled.states[-1].scaled[Model.D:]))
        JointModelChain = Chain(Model.m, State(scaled = Theta_v))
    else:
        JointModelChain = Chain(Model.m, Theta)

    total_acc = np.zeros(iterations)
    total_acc[0] = 1

    v_D = models[-1].D # Dimension of largest model is auxilliary variable size.

    # Initial propbability values.
    log_likelihood = Model.log_likelihood(Theta)
    log_prior = Model.log_prior_density(Theta, v = v, v_D = v_D)


    if user_feedback: print(&#34;Running adapt-RJMH.&#34;)
    for i in range(1, iterations): # Adapt-RJMH algorithm.
        
        if user_feedback:
            cf = i / (iterations - 1)
            print(f&#39;model: {Model.m} progress: [{&#34;#&#34;*round(50*cf)+&#34;-&#34;*round(50*(1-cf))}] {100.*cf:.2f}%\r&#39;, end=&#34;&#34;)

        # Propose a new model and state and calculate the resulting density.
        ProposedModel = random.choice(models)
        Proposed = State(scaled = adapt_RJMH_proposal(Model, ProposedModel, Theta, lv))
        log_likelihood_proposed = ProposedModel.log_likelihood(Proposed)
        log_prior_proposed = ProposedModel.log_prior_density(Proposed, v = v, v_D = v_D)

        # Metropolis acceptance criterion.
        if random.random() &lt; np.exp(log_likelihood_proposed - log_likelihood + log_prior_proposed - log_prior):
            # Accept proposal.
            total_acc[i] = 1

            if Model == ProposedModel: # Intra model move.
                Model.acc.append(1)

            Model = ProposedModel
            Theta = Proposed

            log_likelihood = log_likelihood_proposed
            log_prior = log_prior_proposed
            
        else: # Reject proposal.
            total_acc[i] = 0
            
            if Model == ProposedModel: # Intra model move.
                Model.acc.append(0)
        
        # Update model chain.
        Model.add_state(Theta, adapt = True)
        v = State(scaled = np.concatenate((Theta.scaled, v.scaled[Model.D:])))
        JointModelChain.add_general_state(Model.m, v)

        # Update auxilliary center divergence for new states.
        lv[:Model.D] = Theta.scaled - Model.Center.scaled

    if user_feedback:
        print(f&#34;\n average acc: {np.average(total_acc):4f}&#34;)
        print(&#34;P(m1|y): &#34; + str(1 - np.sum(JointModelChain.model_indices) / iterations))
        print(&#34;P(m2|y): &#34; + str(np.sum(JointModelChain.model_indices) / iterations))

    return JointModelChain



def output_file(Models, JointModelChain, n_epochs, sn, letters, name = &#34;&#34;, event_params = None):
    
    # output File:
    with open(&#34;results/&#34;+name+&#34;-run.txt&#34;, &#34;w&#34;) as file:

        file.write(&#34;Run &#34;+name+&#34;\n&#34;)
        
        # inputs
        file.write(&#34;Inputs:\n&#34;)
        if event_params is not None:
            file.write(&#34;Parameters: &#34;+str(event_params.truth)+&#34;\n&#34;)
        file.write(&#34;Number of observations: &#34;+str(n_epochs)+&#34;, Signal to noise baseline: &#34;+str(sn)+&#34;\n&#34;)
        
        file.write(&#34;\n&#34;)
        file.write(&#34;Run information:\n&#34;)
        file.write(&#34;Iterations: &#34;+str(JointModelChain.n)+&#34;\n&#34;)
        total_acc = 0
        for Model in Models:
            total_acc += np.sum(Model.acc)
        total_acc /= JointModelChain.n
        file.write(&#34;Average acc; Total: &#34;+str(total_acc))

        # results
        file.write(&#34;\n\nResults:\n&#34;)
        for Model in Models:
            # models
            P_Model = Model.Sampled.n/JointModelChain.n
            sd_Model = ((Model.Sampled.n*(1-P_Model)**2 + (JointModelChain.n-Model.Sampled.n)*(0-P_Model)**2) / (JointModelChain.n-1))**0.5
            file.write(&#34;\n&#34;+str(Model.m)+&#34;\nP(m|y): &#34;+str(P_Model)+r&#34;\pm&#34;+str(sd_Model)+&#34;\n&#34;)

            # parameters
            Model_states = Model.Sampled.states_array(scaled = True)
            for i in range(len(Model.Sampled.states[-1].scaled)):
                mu = np.average(Model_states[i, :])
                sd = np.std(Model_states[i, :], ddof = 1)
                file.write(letters[i]+&#34;: mean: &#34;+str(mu)+&#34;, sd: &#34;+str(sd)+&#34; \n&#34;)
    
    return</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sampling.adapt_MH"><code class="name flex">
<span>def <span class="ident">adapt_MH</span></span>(<span>Model, warm_up, iterations, user_feedback=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Performs Adaptive Metropolis Hastings.</p>
<p>Produces a posterior distribution by adapting the proposal process within
one model, as described in Haario et al (2001).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Model</code></strong></dt>
<dd>The model object to sample the distrbution from.</dd>
<dt><strong><code>warm_up</code></strong></dt>
<dd>The integer number of steps without adaption.</dd>
<dt><strong><code>iterations</code></strong></dt>
<dd>The integer number of steps with adaption.</dd>
<dt><strong><code>user_feedback</code></strong></dt>
<dd>(Optional) whether or not to print porgress (Boolean).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>BestTheta</code></dt>
<dd>The state producing the best posterior density visited.</dd>
<dt><code>log_best_posterior</code></dt>
<dd>The best log posterior density visited.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adapt_MH(Model, warm_up, iterations, user_feedback = False):
    &#34;&#34;&#34;Performs Adaptive Metropolis Hastings.
    
    Produces a posterior distribution by adapting the proposal process within 
    one model, as described in Haario et al (2001).

    Args:
        Model: The model object to sample the distrbution from.
        warm_up: The integer number of steps without adaption.
        iterations: The integer number of steps with adaption.
        user_feedback: (Optional) whether or not to print porgress (Boolean).

    Returns:
        BestTheta: The state producing the best posterior density visited.
        log_best_posterior: The best log posterior density visited. 
    &#34;&#34;&#34;

    if warm_up &lt; 5:
        raise ValueError(&#34;Not enough iterations to safely establish an empirical covariance matrix.&#34;)
    
    Theta = Model.center
    BestTheta = Theta

    # Initial propbability values.
    log_likelihood = Model.log_likelihood(Theta)
    log_prior = Model.log_prior_density(Theta)
    log_best_posterior = log_likelihood + log_prior

    # Warm up walk to establish an empirical covariance.
    for i in range(1, warm_up):

        # Propose a new state and calculate the resulting density.
        Proposed = State(scaled = gaussian_proposal(Theta.scaled, Model.covariance))
        log_likelihood_proposed = Model.log_likelihood(Proposed)
        log_prior_proposed = Model.log_prior_density(Proposed)

        # Metropolis acceptance criterion.
        if random.random() &lt; np.exp(log_likelihood_proposed - log_likelihood + log_prior_proposed - log_prior):
            # Accept proposal.
            Theta = Proposed
            log_likelihood = log_likelihood_proposed
            Model.acc.append(1)

            # store best state
            log_posterior = log_likelihood_proposed + log_prior_proposed
            if log_best_posterior &lt; log_posterior:
                log_best_posterior = log_posterior
                BestTheta = Theta

        else: Model.acc.append(0) # reject proposal
        
        # update storage
        Model.add_state(Theta, adapt = False)

    # Calculate intial empirical covariance matrix.
    Model.covariance = np.cov(Model.sampled.states_array(scaled = True))
    Model.covariances.pop()
    Model.covariances.append(Model.covariance)

    # Perform adaptive walk.
    for i in range(warm_up, iterations):

        if user_feedback:
            cf = i / (iterations - 1)
            print(f&#39;log score: {log_best_posterior:.4f}, progress: [{&#34;#&#34;*round(50*cf)+&#34;-&#34;*round(50*(1-cf))}] {100.*cf:.2f}%\r&#39;, end=&#34;&#34;)

        # Propose a new state and calculate the resulting density.
        Proposed = State(scaled = gaussian_proposal(Theta.scaled, Model.covariance))
        log_likelihood_proposed = Model.log_likelihood(Proposed)
        log_prior_proposed = Model.log_prior_density(Proposed)

        # Metropolis acceptance criterion.
        if random.random() &lt; np.exp(log_likelihood_proposed - log_likelihood + log_prior_proposed - log_prior):
            # Accept proposal.
            Theta = Proposed
            log_likelihood = log_likelihood_proposed
            Model.acc.append(1)

            # Store the best state.
            log_posterior = log_likelihood_proposed + log_prior_proposed
            if log_best_posterior &lt; log_posterior:
                log_best_posterior = log_posterior
                BestTheta = Theta

        else: Model.acc.append(0) # Reject proposal.
        
        # Update model chain.
        Model.add_state(Theta, adapt = True)

    if user_feedback:
        print(f&#34;\n model: {Model.m}, average acc: {(np.sum(Model.acc) / (iterations + warm_up)):4f}, best score: {log_best_posterior:.4f}&#34;)

    return BestTheta, log_best_posterior</code></pre>
</details>
</dd>
<dt id="sampling.adapt_RJMH"><code class="name flex">
<span>def <span class="ident">adapt_RJMH</span></span>(<span>models, adapt_MH_warm_up, adapt_MH, initial_n, iterations, user_feedback=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Samples from a joint distribution of models.</p>
<p>Initialises each model with multiple adaptive MH runs. Then uses the resulting
covariances to run adaptive RJMH on all models.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>models</code></strong></dt>
<dd>A list of model objects to sample from.
Should be sorted by increasing dimensionality.</dd>
<dt><strong><code>adapt_MH_warm_up</code></strong></dt>
<dd>The integer number of non-adaptive steps to initilaise with.</dd>
<dt><strong><code>adapt_MH</code></strong></dt>
<dd>The integer number of adaptive steps to initialise with.</dd>
<dt><strong><code>n_repeat</code></strong></dt>
<dd>The integer number of times to try for a better initial run.</dd>
<dt><strong><code>iterations</code></strong></dt>
<dd>The integer number of adaptive RJMH steps.</dd>
<dt><strong><code>user_feedback</code></strong></dt>
<dd>(Optional) whether to print progress (Boolean).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>JointModelChain</code></dt>
<dd>A generalised chain with states from any model.</dd>
<dt><code>total_acc</code></dt>
<dd>A list of binary values, 1 if the state proposed was accepted,
0 if it was rejected, associated with the joint model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adapt_RJMH(models, adapt_MH_warm_up, adapt_MH, initial_n, iterations, user_feedback = False):
    &#34;&#34;&#34;Samples from a joint distribution of models.
    
    Initialises each model with multiple adaptive MH runs. Then uses the resulting
    covariances to run adaptive RJMH on all models.

    Args:
        models: A list of model objects to sample from. 
            Should be sorted by increasing dimensionality.
        adapt_MH_warm_up: The integer number of non-adaptive steps to initilaise with.
        adapt_MH: The integer number of adaptive steps to initialise with.
        n_repeat: The integer number of times to try for a better initial run.
        iterations: The integer number of adaptive RJMH steps.
        user_feedback: (Optional) whether to print progress (Boolean).

    Returns:
        JointModelChain: A generalised chain with states from any model.
        total_acc: A list of binary values, 1 if the state proposed was accepted,
            0 if it was rejected, associated with the joint model.
    &#34;&#34;&#34;

    # Initialise model chains.
    for Model in models:
        Model = initialise_RJMH_model(Model, adapt_MH_warm_up, adapt_MH, initial_n, user_feedback = user_feedback)

    random.seed(42)

    # Choose a random model to start in.
    Model = random.choice(models)
    Theta = Model.Sampled.states[-1] # Final state in model&#39;s warmup chain.

    v = models[-1].Sampled.states[-1] # Auxiliary variables final state in super set model
    lv = models[-1].Sampled.states[-1].scaled - models[-1].Center.scaled # auxiliary variables offset from center

    # Create joint model as initial theta appended to auxiliary variables.
    initial_superset = models[-1].D - Model.D
    if initial_superset &gt; 0: # If random choice was a subset model
        Theta_v = np.concatenate((Theta.scaled, models[-1].Sampled.states[-1].scaled[Model.D:]))
        JointModelChain = Chain(Model.m, State(scaled = Theta_v))
    else:
        JointModelChain = Chain(Model.m, Theta)

    total_acc = np.zeros(iterations)
    total_acc[0] = 1

    v_D = models[-1].D # Dimension of largest model is auxilliary variable size.

    # Initial propbability values.
    log_likelihood = Model.log_likelihood(Theta)
    log_prior = Model.log_prior_density(Theta, v = v, v_D = v_D)


    if user_feedback: print(&#34;Running adapt-RJMH.&#34;)
    for i in range(1, iterations): # Adapt-RJMH algorithm.
        
        if user_feedback:
            cf = i / (iterations - 1)
            print(f&#39;model: {Model.m} progress: [{&#34;#&#34;*round(50*cf)+&#34;-&#34;*round(50*(1-cf))}] {100.*cf:.2f}%\r&#39;, end=&#34;&#34;)

        # Propose a new model and state and calculate the resulting density.
        ProposedModel = random.choice(models)
        Proposed = State(scaled = adapt_RJMH_proposal(Model, ProposedModel, Theta, lv))
        log_likelihood_proposed = ProposedModel.log_likelihood(Proposed)
        log_prior_proposed = ProposedModel.log_prior_density(Proposed, v = v, v_D = v_D)

        # Metropolis acceptance criterion.
        if random.random() &lt; np.exp(log_likelihood_proposed - log_likelihood + log_prior_proposed - log_prior):
            # Accept proposal.
            total_acc[i] = 1

            if Model == ProposedModel: # Intra model move.
                Model.acc.append(1)

            Model = ProposedModel
            Theta = Proposed

            log_likelihood = log_likelihood_proposed
            log_prior = log_prior_proposed
            
        else: # Reject proposal.
            total_acc[i] = 0
            
            if Model == ProposedModel: # Intra model move.
                Model.acc.append(0)
        
        # Update model chain.
        Model.add_state(Theta, adapt = True)
        v = State(scaled = np.concatenate((Theta.scaled, v.scaled[Model.D:])))
        JointModelChain.add_general_state(Model.m, v)

        # Update auxilliary center divergence for new states.
        lv[:Model.D] = Theta.scaled - Model.Center.scaled

    if user_feedback:
        print(f&#34;\n average acc: {np.average(total_acc):4f}&#34;)
        print(&#34;P(m1|y): &#34; + str(1 - np.sum(JointModelChain.model_indices) / iterations))
        print(&#34;P(m2|y): &#34; + str(np.sum(JointModelChain.model_indices) / iterations))

    return JointModelChain</code></pre>
</details>
</dd>
<dt id="sampling.adapt_RJMH_proposal"><code class="name flex">
<span>def <span class="ident">adapt_RJMH_proposal</span></span>(<span>Model, ProposedModel, Theta, lv)</span>
</code></dt>
<dd>
<div class="desc"><p>Performs an Adaptive Reversible-Jump Metropolis Hastings proposal.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Model</code></strong></dt>
<dd>The model to jump from.</dd>
<dt><strong><code>ProposedModel</code></strong></dt>
<dd>The model to jump to.</dd>
<dt><strong><code>Theta</code></strong></dt>
<dd>The state to jump from.</dd>
<dt><strong><code>lv</code></strong></dt>
<dd>A list of the current auxilliary variables center divergence.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ProposedTheta</code></dt>
<dd>A state proposed to jump to.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adapt_RJMH_proposal(Model, ProposedModel, Theta, lv):
    &#34;&#34;&#34;Performs an Adaptive Reversible-Jump Metropolis Hastings proposal.
    
    Args:
        Model: The model to jump from.
        ProposedModel: The model to jump to.
        Theta: The state to jump from.
        lv: A list of the current auxilliary variables center divergence.

    Returns:
        ProposedTheta: A state proposed to jump to.
    &#34;&#34;&#34;
    l = Theta.scaled - Model.Center.scaled # Offset from initial model&#39;s centre.

    if Model.m == ProposedModel.m: # Intra-model move.

        # Use the covariance at the proposed model&#39;s center for local shape.
        u = gaussian_proposal(np.zeros((ProposedModel.D)), ProposedModel.covariance)
        ProposedTheta = u + l + ProposedModel.Center.scaled
        
        return ProposedTheta

    else: # Inter-model move.
        
        s = abs(Model.D - ProposedModel.D) # Subset size.

        # Use superset model covariance
        if ProposedModel.D &gt; Model.D: # Proposed is superset
            cov = ProposedModel.covariance
        else: # Proposed is subset
            cov = Model.covariance

        c_11 = cov[:s, :s] # Covariance matrix of shared parameters.
        c_12 = cov[:s, s:] # Covariances, not variances.
        c_21 = cov[s:, :s] # Same as above.
        c_22 = cov[s:, s:] # Covariance matrix of non-shared.
        c_22_inv = np.linalg.inv(c_22)

        conditioned_cov = c_11 - c_12.dot(c_22_inv).dot(c_21)

        if ProposedModel.D &lt; Model.D: # Jump to smaller model. Fix non-shared parameters.

            u = gaussian_proposal(np.zeros((s)), conditioned_cov)
            proposed_theta = u + l[:s] + ProposedModel.Center.scaled

            return proposed_theta

        if ProposedModel.D &gt; Model.D: # Jump to larger model. Append v.

            u = gaussian_proposal(np.zeros((s)), conditioned_cov)
            shared_map = u + l[:s] + ProposedModel.Center.scaled[:s]
            non_shared_map = lv[s:] + ProposedModel.Center.scaled[s:]
            map = np.concatenate((shared_map, non_shared_map))
            proposed_theta = map

            return proposed_theta</code></pre>
</details>
</dd>
<dt id="sampling.check_symmetric"><code class="name flex">
<span>def <span class="ident">check_symmetric</span></span>(<span>A, tol=1e-16)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_symmetric(A, tol = 1e-16):
    return np.all(np.abs(A-A.T) &lt; tol)</code></pre>
</details>
</dd>
<dt id="sampling.gaussian_proposal"><code class="name flex">
<span>def <span class="ident">gaussian_proposal</span></span>(<span>theta, covariance)</span>
</code></dt>
<dd>
<div class="desc"><p>Samples a gaussian move.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gaussian_proposal(theta, covariance):
    &#34;&#34;&#34;Samples a gaussian move.&#34;&#34;&#34;
    return multivariate_normal.rvs(mean = theta, cov = covariance)</code></pre>
</details>
</dd>
<dt id="sampling.initialise_RJMH_model"><code class="name flex">
<span>def <span class="ident">initialise_RJMH_model</span></span>(<span>EmptyModel, warm_up, iterations, n_repeat, user_feedback=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Prepares a model for the adaptive RJ algorithm.</p>
<p>Repeats the adaptive MH warmup process for a model, storing the best run.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>EmptyModel</code></strong></dt>
<dd>The initialised model object.</dd>
<dt><strong><code>warm_up</code></strong></dt>
<dd>The integer number of non-adaptive steps.</dd>
<dt><strong><code>iterations</code></strong></dt>
<dd>The integer number of adaptive steps.</dd>
<dt><strong><code>n_repeat</code></strong></dt>
<dd>The integer number of times to try for a better run.</dd>
<dt><strong><code>user_feedback</code></strong></dt>
<dd>(Optional) whether to print progress (Boolean).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>IncumbentModel</code></dt>
<dd>The model with the states from the best run.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialise_RJMH_model(EmptyModel, warm_up, iterations, n_repeat, user_feedback = False):
    &#34;&#34;&#34;Prepares a model for the adaptive RJ algorithm.
    
    Repeats the adaptive MH warmup process for a model, storing the best run.

    Args:
        EmptyModel: The initialised model object.
        warm_up: The integer number of non-adaptive steps.
        iterations: The integer number of adaptive steps.
        n_repeat: The integer number of times to try for a better run.
        user_feedback: (Optional) whether to print progress (Boolean).

    Returns:
        IncumbentModel: The model with the states from the best run.
    &#34;&#34;&#34;

    inc_log_best_posterior = -math.inf # Initialise incumbent posterior to always lose

    for i in range(n_repeat):
        
        if user_feedback:
            print(&#34;Running the &#34;+str(i+1)+&#34;/&#34;+str(n_repeat)+&#34;th initialisation per model\n&#34;)

        Model = deepcopy(EmptyModel) # Fresh model.

        # Run adaptive MH.
        BestTheta, log_best_posterior = adapt_MH(Model, warm_up, iterations, user_feedback = user_feedback)

        # Keep the best posterior density run.
        if inc_log_best_posterior &lt; log_best_posterior:
            IncumbentModel = Model
            IncumbentModel.Center = BestTheta

    return IncumbentModel</code></pre>
</details>
</dd>
<dt id="sampling.iterative_covariance"><code class="name flex">
<span>def <span class="ident">iterative_covariance</span></span>(<span>cov, x, x_mu, n, s, I, eps=1e-12)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iterative_covariance(cov, x, x_mu, n, s, I, eps = 1e-12):
    return (n-1)/n * cov + s/(n+1) * np.outer(x - x_mu, x - x_mu) + s*eps*I/n</code></pre>
</details>
</dd>
<dt id="sampling.iterative_mean"><code class="name flex">
<span>def <span class="ident">iterative_mean</span></span>(<span>x_mu, x, n)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iterative_mean(x_mu, x, n):
    return (x_mu * n + x)/(n + 1)</code></pre>
</details>
</dd>
<dt id="sampling.output_file"><code class="name flex">
<span>def <span class="ident">output_file</span></span>(<span>Models, JointModelChain, n_epochs, sn, letters, name='', event_params=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def output_file(Models, JointModelChain, n_epochs, sn, letters, name = &#34;&#34;, event_params = None):
    
    # output File:
    with open(&#34;results/&#34;+name+&#34;-run.txt&#34;, &#34;w&#34;) as file:

        file.write(&#34;Run &#34;+name+&#34;\n&#34;)
        
        # inputs
        file.write(&#34;Inputs:\n&#34;)
        if event_params is not None:
            file.write(&#34;Parameters: &#34;+str(event_params.truth)+&#34;\n&#34;)
        file.write(&#34;Number of observations: &#34;+str(n_epochs)+&#34;, Signal to noise baseline: &#34;+str(sn)+&#34;\n&#34;)
        
        file.write(&#34;\n&#34;)
        file.write(&#34;Run information:\n&#34;)
        file.write(&#34;Iterations: &#34;+str(JointModelChain.n)+&#34;\n&#34;)
        total_acc = 0
        for Model in Models:
            total_acc += np.sum(Model.acc)
        total_acc /= JointModelChain.n
        file.write(&#34;Average acc; Total: &#34;+str(total_acc))

        # results
        file.write(&#34;\n\nResults:\n&#34;)
        for Model in Models:
            # models
            P_Model = Model.Sampled.n/JointModelChain.n
            sd_Model = ((Model.Sampled.n*(1-P_Model)**2 + (JointModelChain.n-Model.Sampled.n)*(0-P_Model)**2) / (JointModelChain.n-1))**0.5
            file.write(&#34;\n&#34;+str(Model.m)+&#34;\nP(m|y): &#34;+str(P_Model)+r&#34;\pm&#34;+str(sd_Model)+&#34;\n&#34;)

            # parameters
            Model_states = Model.Sampled.states_array(scaled = True)
            for i in range(len(Model.Sampled.states[-1].scaled)):
                mu = np.average(Model_states[i, :])
                sd = np.std(Model_states[i, :], ddof = 1)
                file.write(letters[i]+&#34;: mean: &#34;+str(mu)+&#34;, sd: &#34;+str(sd)+&#34; \n&#34;)
    
    return</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sampling.Chain"><code class="flex name class">
<span>class <span class="ident">Chain</span></span>
<span>(</span><span>m, state)</span>
</code></dt>
<dd>
<div class="desc"><p>A collection of states.</p>
<p>Describes a markov chain, perhaps from a joint model space.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>states</code></strong></dt>
<dd>A list of state objects in the chain.</dd>
<dt><strong><code>model_indices</code></strong></dt>
<dd>A list of the models the states are from. </dd>
<dt><strong><code>n</code></strong></dt>
<dd>The number of states in the chain.</dd>
</dl>
<p>Initialises the chain with one state from one model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>state</code></strong></dt>
<dd>The state object.</dd>
<dt><strong><code>m</code></strong></dt>
<dd>The index of the model the state is from.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Chain(object):
    &#34;&#34;&#34;A collection of states.

    Describes a markov chain, perhaps from a joint model space.

    Attributes:
        states: A list of state objects in the chain.
        model_indices: A list of the models the states are from. 
        n: The number of states in the chain.
    &#34;&#34;&#34;

    def __init__(self, m, state):
        &#34;&#34;&#34;Initialises the chain with one state from one model.

        Args:
            state: The state object.
            m: The index of the model the state is from.
        &#34;&#34;&#34;
        self.states = [state]
        self.model_indices = [m]
        self.n = 1

    def add_general_state(self, m, state):
        &#34;&#34;&#34;Adds a state in a model to the chain.

        Args:
            state: The state object.
            m: The index of the model the state is from.
        &#34;&#34;&#34;
        self.states.append(state)
        self.model_indices.append(m)
        self.n += 1
        return

    def states_array(self, scaled = True):
        &#34;&#34;&#34;Creates a numpy array of all states in the chain.

        Args:
            scale: (Optional) whether the array should be in scaled or true 
                    space (Boolean).

        Returns:
            chain_array: The numpy array of all state parameters. Columns are
                        states, rows are parameters for all states.
        &#34;&#34;&#34;
        n_states = len(self.states)
        D_state = len(self.states[-1].scaled)
        
        chain_array = np.zeros((D_state, n_states))

        if scaled:
            for i in range(n_states):
                chain_array[:, i] = self.states[i].scaled

        else:
            for i in range(n_states):
                chain_array[:, i] = self.states[i].truth

        return chain_array</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="sampling.Chain.add_general_state"><code class="name flex">
<span>def <span class="ident">add_general_state</span></span>(<span>self, m, state)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a state in a model to the chain.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>state</code></strong></dt>
<dd>The state object.</dd>
<dt><strong><code>m</code></strong></dt>
<dd>The index of the model the state is from.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_general_state(self, m, state):
    &#34;&#34;&#34;Adds a state in a model to the chain.

    Args:
        state: The state object.
        m: The index of the model the state is from.
    &#34;&#34;&#34;
    self.states.append(state)
    self.model_indices.append(m)
    self.n += 1
    return</code></pre>
</details>
</dd>
<dt id="sampling.Chain.states_array"><code class="name flex">
<span>def <span class="ident">states_array</span></span>(<span>self, scaled=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a numpy array of all states in the chain.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>scale</code></strong></dt>
<dd>(Optional) whether the array should be in scaled or true
space (Boolean).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>chain_array</code></dt>
<dd>The numpy array of all state parameters. Columns are
states, rows are parameters for all states.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def states_array(self, scaled = True):
    &#34;&#34;&#34;Creates a numpy array of all states in the chain.

    Args:
        scale: (Optional) whether the array should be in scaled or true 
                space (Boolean).

    Returns:
        chain_array: The numpy array of all state parameters. Columns are
                    states, rows are parameters for all states.
    &#34;&#34;&#34;
    n_states = len(self.states)
    D_state = len(self.states[-1].scaled)
    
    chain_array = np.zeros((D_state, n_states))

    if scaled:
        for i in range(n_states):
            chain_array[:, i] = self.states[i].scaled

    else:
        for i in range(n_states):
            chain_array[:, i] = self.states[i].truth

    return chain_array</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="sampling.Log_Uniform"><code class="flex name class">
<span>class <span class="ident">Log_Uniform</span></span>
<span>(</span><span>left, right)</span>
</code></dt>
<dd>
<div class="desc"><p>A log uniform distribution.</p>
<p>The log of the data is uniformly distributed.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>lb</code></strong></dt>
<dd>A float lower bound for support.</dd>
<dt><strong><code>rb</code></strong></dt>
<dd>A float upper bound for support.</dd>
</dl>
<p>Initialises Log uniform with bounds and sampler.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Log_Uniform(object):
    &#34;&#34;&#34;A log uniform distribution.

    The log of the data is uniformly distributed.

    Attributes:
        lb: A float lower bound for support.
        rb: A float upper bound for support.
    &#34;&#34;&#34;

    def __init__(self, left, right):
        &#34;&#34;&#34;Initialises Log uniform with bounds and sampler.&#34;&#34;&#34;
        self.lb = left
        self.rb = right
        self.dist = loguniform(left, right)

    def in_bound(self, x):
        &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
        if self.lb &lt;= x &lt;= self.rb: return 1
        else: return 0

    def log_pdf(self, x):
        &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
        return self.dist.logpdf(x)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="sampling.Log_Uniform.in_bound"><code class="name flex">
<span>def <span class="ident">in_bound</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if value is in support.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def in_bound(self, x):
    &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
    if self.lb &lt;= x &lt;= self.rb: return 1
    else: return 0</code></pre>
</details>
</dd>
<dt id="sampling.Log_Uniform.log_pdf"><code class="name flex">
<span>def <span class="ident">log_pdf</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate log probability density.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_pdf(self, x):
    &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
    return self.dist.logpdf(x)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="sampling.Model"><code class="flex name class">
<span>class <span class="ident">Model</span></span>
<span>(</span><span>m, D, Center, priors, covariance, data, log_likelihood_fnc)</span>
</code></dt>
<dd>
<div class="desc"><p>A model to describe a probability distribution.</p>
<p>Contains a chain of states from this model, as well as information
from this. Adapts a covariance matrix iteratively with each new state,
and stores a guess at a maximum posterior density estimate.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>m</code></strong></dt>
<dd>The integer model index.</dd>
<dt><strong><code>D</code></strong></dt>
<dd>The integer dimensionality of a state in the model.</dd>
<dt><strong><code>priors</code></strong></dt>
<dd>List of prior distributions for state parameter values.</dd>
<dt><strong><code>sampled</code></strong></dt>
<dd>A chain of states sampled from the model's distribution.</dd>
<dt><strong><code>scaled_avg_state</code></strong></dt>
<dd>The scaled average parameter values of the chain.</dd>
<dt><strong><code>center</code></strong></dt>
<dd>The state of the best guess at a maximum posterior density.</dd>
<dt><strong><code>covariance</code></strong></dt>
<dd>The current covariance matrix, based on all states.</dd>
<dt><strong><code>covariances</code></strong></dt>
<dd>A list of all previous covariance matrices.</dd>
<dt><strong><code>acc</code></strong></dt>
<dd>A list of binary values, 1 if the state proposed was accepted,
0 if it was rejected.</dd>
<dt><strong><code>data</code></strong></dt>
<dd>A MulensData object for photometry readings from the
microlensing event.</dd>
<dt><strong><code>log_likelihood</code></strong></dt>
<dd>A function to calculate the log likelihood a state is
from this model.</dd>
<dt><strong><code>I</code></strong></dt>
<dd>An identity matrix the size of D.</dd>
<dt><strong><code>s</code></strong></dt>
<dd>A scalar (see Haario et al 2001).</dd>
</dl>
<p>Initialises the model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Model(object):
    &#34;&#34;&#34;A model to describe a probability distribution.

    Contains a chain of states from this model, as well as information
    from this. Adapts a covariance matrix iteratively with each new state,
    and stores a guess at a maximum posterior density estimate.

    Attributes:
        m: The integer model index.
        D: The integer dimensionality of a state in the model.
        priors: List of prior distributions for state parameter values.
        sampled: A chain of states sampled from the model&#39;s distribution.
        scaled_avg_state: The scaled average parameter values of the chain.
        center: The state of the best guess at a maximum posterior density.
        covariance: The current covariance matrix, based on all states.
        covariances: A list of all previous covariance matrices.
        acc: A list of binary values, 1 if the state proposed was accepted,
            0 if it was rejected.
        data: A MulensData object for photometry readings from the 
            microlensing event.
        log_likelihood: A function to calculate the log likelihood a state is
            from this model.
        I: An identity matrix the size of D.
        s: A scalar (see Haario et al 2001).
    &#34;&#34;&#34;

    def __init__(self, m, D, Center, priors, covariance, data, log_likelihood_fnc):
        &#34;&#34;&#34;Initialises the model.&#34;&#34;&#34;
        self.m = m
        self.D = D
        self.priors = priors
        self.Center = Center
        self.Sampled = Chain(m, Center)
        self.scaled_avg_state = Center.scaled
        self.acc = [1] # First state always accepted
        self.covariance = covariance
        self.covariances = [covariance]

        self.data = data
        # Model&#39;s custom likelihood function
        self.log_likelihood = MethodType(log_likelihood_fnc, self)

        self.I = np.identity(D)
        self.s = 2.4**2 / D # Arbitrary(ish), good value from Haario et al 2001.
    
    def add_state(self, theta, adapt = True):
        &#34;&#34;&#34;Adds a sampled state to the model.

        Args:
            theta: The state to add.
            adapt: (Optional) whether to adjust the covariance matrix, based
                on the new state (Boolean).
        &#34;&#34;&#34;
        self.Sampled.n += 1
        self.Sampled.states.append(theta)

        if adapt:
            self.covariance = iterative_covariance(self.covariance, theta.scaled, self.scaled_avg_state, self.Sampled.n, self.s, self.I)

        self.covariances.append(self.covariance)
        self.scaled_avg_state = iterative_mean(self.scaled_avg_state, theta.scaled, self.Sampled.n)

        return

    def log_likelihood(self, theta):
        &#34;&#34;&#34;Empty method for object model dependant assignment with MethodType.&#34;&#34;&#34;
        raise ValueError(&#34;No likelihood method assigned for model&#34;)

    def log_prior_density(self, theta, v = None, v_D = None):
        &#34;&#34;&#34;Calculates the log prior density of a state in the model.

        Optionally adjusts this log density when using auxilliary vriables.

        Args:
            theta: The state to calculate the log prior density for.
            v: (Optional) The state of all auxiliary variables.
            v_D: (Optional) the integer dimensionality of to use to adjust v.

        Returns:
            log_prior_product: The log prior probability density.
        &#34;&#34;&#34;    
        log_prior_product = 0.

        # cycle through parameters
        for p in range(self.D):

            # product using log rules
            log_prior_product += (self.priors[p].log_pdf(theta.truth[p]))

        # cycle through auxiliary parameters if v and v_D passed
        if v is not None or v_D is not None:
            if v is not None and v_D is not None:
                for p in range(self.D, v_D):
                    
                    # product using log rules
                    log_prior_product += (self.priors[p].log_pdf(v.truth[p]))

            else: raise ValueError(&#34;Only one of v or v_D passed.&#34;)

        return log_prior_product</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="sampling.Model.add_state"><code class="name flex">
<span>def <span class="ident">add_state</span></span>(<span>self, theta, adapt=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a sampled state to the model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>theta</code></strong></dt>
<dd>The state to add.</dd>
<dt><strong><code>adapt</code></strong></dt>
<dd>(Optional) whether to adjust the covariance matrix, based
on the new state (Boolean).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_state(self, theta, adapt = True):
    &#34;&#34;&#34;Adds a sampled state to the model.

    Args:
        theta: The state to add.
        adapt: (Optional) whether to adjust the covariance matrix, based
            on the new state (Boolean).
    &#34;&#34;&#34;
    self.Sampled.n += 1
    self.Sampled.states.append(theta)

    if adapt:
        self.covariance = iterative_covariance(self.covariance, theta.scaled, self.scaled_avg_state, self.Sampled.n, self.s, self.I)

    self.covariances.append(self.covariance)
    self.scaled_avg_state = iterative_mean(self.scaled_avg_state, theta.scaled, self.Sampled.n)

    return</code></pre>
</details>
</dd>
<dt id="sampling.Model.log_likelihood"><code class="name flex">
<span>def <span class="ident">log_likelihood</span></span>(<span>self, theta)</span>
</code></dt>
<dd>
<div class="desc"><p>Empty method for object model dependant assignment with MethodType.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_likelihood(self, theta):
    &#34;&#34;&#34;Empty method for object model dependant assignment with MethodType.&#34;&#34;&#34;
    raise ValueError(&#34;No likelihood method assigned for model&#34;)</code></pre>
</details>
</dd>
<dt id="sampling.Model.log_prior_density"><code class="name flex">
<span>def <span class="ident">log_prior_density</span></span>(<span>self, theta, v=None, v_D=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the log prior density of a state in the model.</p>
<p>Optionally adjusts this log density when using auxilliary vriables.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>theta</code></strong></dt>
<dd>The state to calculate the log prior density for.</dd>
<dt><strong><code>v</code></strong></dt>
<dd>(Optional) The state of all auxiliary variables.</dd>
<dt><strong><code>v_D</code></strong></dt>
<dd>(Optional) the integer dimensionality of to use to adjust v.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>log_prior_product</code></dt>
<dd>The log prior probability density.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_prior_density(self, theta, v = None, v_D = None):
    &#34;&#34;&#34;Calculates the log prior density of a state in the model.

    Optionally adjusts this log density when using auxilliary vriables.

    Args:
        theta: The state to calculate the log prior density for.
        v: (Optional) The state of all auxiliary variables.
        v_D: (Optional) the integer dimensionality of to use to adjust v.

    Returns:
        log_prior_product: The log prior probability density.
    &#34;&#34;&#34;    
    log_prior_product = 0.

    # cycle through parameters
    for p in range(self.D):

        # product using log rules
        log_prior_product += (self.priors[p].log_pdf(theta.truth[p]))

    # cycle through auxiliary parameters if v and v_D passed
    if v is not None or v_D is not None:
        if v is not None and v_D is not None:
            for p in range(self.D, v_D):
                
                # product using log rules
                log_prior_product += (self.priors[p].log_pdf(v.truth[p]))

        else: raise ValueError(&#34;Only one of v or v_D passed.&#34;)

    return log_prior_product</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="sampling.State"><code class="flex name class">
<span>class <span class="ident">State</span></span>
<span>(</span><span>truth=None, scaled=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A sampled state from a model's probability distribution.</p>
<p>Describes a point in both scaled and unscaled space. The scaling is
hardcoded but can be extended per application. Currently log10 scaling
the fourth parameter. In microlensing applications, this is q,
the mass ratio.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>truth</code></strong></dt>
<dd>A list of parameter values for the state, in true space.</dd>
<dt><strong><code>scaled</code></strong></dt>
<dd>A list of parameter values for the state, in scaled space.</dd>
<dt><strong><code>D</code></strong></dt>
<dd>The integer dimensionality of the state.</dd>
</dl>
<p>Initialises state with truth, scaled, and D values.</p>
<h2 id="args">Args</h2>
<p>either a list of parameter values in the true or scaled states.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class State(object):
    &#34;&#34;&#34;A sampled state from a model&#39;s probability distribution.

    Describes a point in both scaled and unscaled space. The scaling is 
    hardcoded but can be extended per application. Currently log10 scaling 
    the fourth parameter. In microlensing applications, this is q,
    the mass ratio.

    Attributes:
        truth: A list of parameter values for the state, in true space.
        scaled: A list of parameter values for the state, in scaled space.
        D: The integer dimensionality of the state.
    &#34;&#34;&#34;

    def __init__(self, truth = None, scaled = None):
        &#34;&#34;&#34;Initialises state with truth, scaled, and D values.

        Args:
            either a list of parameter values in the true or scaled states.
        &#34;&#34;&#34;        
        if truth is not None:
            self.truth = truth
            self.D = len(truth)

            self.scaled = deepcopy(self.truth)
            for p in range(self.D):
                if p == 3:
                    self.scaled[p] = np.log10(self.truth[p])
        
        elif scaled is not None:
            self.scaled = scaled
            self.D = len(scaled)

            self.truth = deepcopy(self.scaled)
            for p in range(self.D):
                if p == 3:
                    self.truth[p] = 10**(self.scaled[p])

        else:   raise ValueError(&#34;Assigned null state&#34;)</code></pre>
</details>
</dd>
<dt id="sampling.Truncated_Log_Normal"><code class="flex name class">
<span>class <span class="ident">Truncated_Log_Normal</span></span>
<span>(</span><span>left, right, mu, sd)</span>
</code></dt>
<dd>
<div class="desc"><p>A truncated log normal distribution.</p>
<p>The log of the data is normally distributed, and the data is constrained.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>lb</code></strong></dt>
<dd>A float lower bound for support.</dd>
<dt><strong><code>rb</code></strong></dt>
<dd>A float upper bound for support.</dd>
</dl>
<p>Initialises Truncated log normal with bounds and sampler.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mu</code></strong></dt>
<dd>The scalar mean of the underlying normal distrubtion in true
space.</dd>
<dt><strong><code>sd</code></strong></dt>
<dd>The scalar standard deviation of the underlying normal
distribution in true space.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Truncated_Log_Normal(object):
    &#34;&#34;&#34;A truncated log normal distribution.

    The log of the data is normally distributed, and the data is constrained.

    Attributes:
        lb: A float lower bound for support.
        rb: A float upper bound for support.
    &#34;&#34;&#34;

    def __init__(self, left, right, mu, sd):
        &#34;&#34;&#34;Initialises Truncated log normal with bounds and sampler.

        Args:
            mu: The scalar mean of the underlying normal distrubtion in true 
                space.
            sd: The scalar standard deviation of the underlying normal 
                distribution in true space.
        &#34;&#34;&#34;
        self.lb = left
        self.rb = right
        self.dist = lognorm(scale = np.exp(np.log(mu)), s = (np.log(sd))) # Scipy shape parameters.

        # Probability that is otherwise truncated to zero, distributed uniformly (aprroximation).
        self.truncation = (self.dist.cdf(left) + 1 - self.dist.cdf(right)) / (right - left)

    def in_bound(self, x):
        &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
        if self.lb &lt;= x &lt;= self.rb: return 1
        else: return 0

    def log_pdf(self, x):
        &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
        if self.lb &lt;= x &lt;= self.rb: return np.log(self.dist.pdf(x) + self.truncation)
        else: return -math.inf # If out of support.</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="sampling.Truncated_Log_Normal.in_bound"><code class="name flex">
<span>def <span class="ident">in_bound</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if value is in support.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def in_bound(self, x):
    &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
    if self.lb &lt;= x &lt;= self.rb: return 1
    else: return 0</code></pre>
</details>
</dd>
<dt id="sampling.Truncated_Log_Normal.log_pdf"><code class="name flex">
<span>def <span class="ident">log_pdf</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate log probability density.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_pdf(self, x):
    &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
    if self.lb &lt;= x &lt;= self.rb: return np.log(self.dist.pdf(x) + self.truncation)
    else: return -math.inf # If out of support.</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="sampling.Uniform"><code class="flex name class">
<span>class <span class="ident">Uniform</span></span>
<span>(</span><span>left, right)</span>
</code></dt>
<dd>
<div class="desc"><p>A uniform distribution.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>lb</code></strong></dt>
<dd>A float lower bound for support.</dd>
<dt><strong><code>rb</code></strong></dt>
<dd>A float upper bound for support.</dd>
</dl>
<p>Initialises Uniform with bounds and sampler.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Uniform(object):
    &#34;&#34;&#34;A uniform distribution.

    Attributes:
        lb: A float lower bound for support.
        rb: A float upper bound for support.
    &#34;&#34;&#34;

    def __init__(self, left, right):
        &#34;&#34;&#34;Initialises Uniform with bounds and sampler.&#34;&#34;&#34;
        self.lb = left
        self.rb = right
        self.dist = uniform(left, right)

    def in_bound(self, x):
        &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
        if self.lb &lt;= x &lt;= self.rb: return 1
        else: return 0

    def log_pdf(self, x):
        &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
        return self.dist.logpdf(x)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="sampling.Uniform.in_bound"><code class="name flex">
<span>def <span class="ident">in_bound</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if value is in support.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def in_bound(self, x):
    &#34;&#34;&#34;Check if value is in support.&#34;&#34;&#34;
    if self.lb &lt;= x &lt;= self.rb: return 1
    else: return 0</code></pre>
</details>
</dd>
<dt id="sampling.Uniform.log_pdf"><code class="name flex">
<span>def <span class="ident">log_pdf</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate log probability density.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_pdf(self, x):
    &#34;&#34;&#34;Calculate log probability density.&#34;&#34;&#34;
    return self.dist.logpdf(x)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sampling.adapt_MH" href="#sampling.adapt_MH">adapt_MH</a></code></li>
<li><code><a title="sampling.adapt_RJMH" href="#sampling.adapt_RJMH">adapt_RJMH</a></code></li>
<li><code><a title="sampling.adapt_RJMH_proposal" href="#sampling.adapt_RJMH_proposal">adapt_RJMH_proposal</a></code></li>
<li><code><a title="sampling.check_symmetric" href="#sampling.check_symmetric">check_symmetric</a></code></li>
<li><code><a title="sampling.gaussian_proposal" href="#sampling.gaussian_proposal">gaussian_proposal</a></code></li>
<li><code><a title="sampling.initialise_RJMH_model" href="#sampling.initialise_RJMH_model">initialise_RJMH_model</a></code></li>
<li><code><a title="sampling.iterative_covariance" href="#sampling.iterative_covariance">iterative_covariance</a></code></li>
<li><code><a title="sampling.iterative_mean" href="#sampling.iterative_mean">iterative_mean</a></code></li>
<li><code><a title="sampling.output_file" href="#sampling.output_file">output_file</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sampling.Chain" href="#sampling.Chain">Chain</a></code></h4>
<ul class="">
<li><code><a title="sampling.Chain.add_general_state" href="#sampling.Chain.add_general_state">add_general_state</a></code></li>
<li><code><a title="sampling.Chain.states_array" href="#sampling.Chain.states_array">states_array</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sampling.Log_Uniform" href="#sampling.Log_Uniform">Log_Uniform</a></code></h4>
<ul class="">
<li><code><a title="sampling.Log_Uniform.in_bound" href="#sampling.Log_Uniform.in_bound">in_bound</a></code></li>
<li><code><a title="sampling.Log_Uniform.log_pdf" href="#sampling.Log_Uniform.log_pdf">log_pdf</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sampling.Model" href="#sampling.Model">Model</a></code></h4>
<ul class="">
<li><code><a title="sampling.Model.add_state" href="#sampling.Model.add_state">add_state</a></code></li>
<li><code><a title="sampling.Model.log_likelihood" href="#sampling.Model.log_likelihood">log_likelihood</a></code></li>
<li><code><a title="sampling.Model.log_prior_density" href="#sampling.Model.log_prior_density">log_prior_density</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sampling.State" href="#sampling.State">State</a></code></h4>
</li>
<li>
<h4><code><a title="sampling.Truncated_Log_Normal" href="#sampling.Truncated_Log_Normal">Truncated_Log_Normal</a></code></h4>
<ul class="">
<li><code><a title="sampling.Truncated_Log_Normal.in_bound" href="#sampling.Truncated_Log_Normal.in_bound">in_bound</a></code></li>
<li><code><a title="sampling.Truncated_Log_Normal.log_pdf" href="#sampling.Truncated_Log_Normal.log_pdf">log_pdf</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sampling.Uniform" href="#sampling.Uniform">Uniform</a></code></h4>
<ul class="">
<li><code><a title="sampling.Uniform.in_bound" href="#sampling.Uniform.in_bound">in_bound</a></code></li>
<li><code><a title="sampling.Uniform.log_pdf" href="#sampling.Uniform.log_pdf">log_pdf</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>